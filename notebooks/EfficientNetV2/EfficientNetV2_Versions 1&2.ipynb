{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11bc5604"
   },
   "source": [
    "# EfficientNet Image Classification\n",
    "This notebook trains and tests versions 1 & 2 of the EfficientNet model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1fe9579"
   },
   "source": [
    "## 1. Mount Google Drive (Colab Only)\n",
    "This section connects to Google Drive to access the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32872,
     "status": "ok",
     "timestamp": 1743411793509,
     "user": {
      "displayName": "nat ang",
      "userId": "01830563404866135370"
     },
     "user_tz": -480
    },
    "id": "ULgK9_0az7jJ",
    "outputId": "42d8094f-efec-487f-8407-0b3aab43257d"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DATASET_PATH = '/content/drive/My Drive/50.021 Artificial Intelligence Group Assignment'\n",
    "\n",
    "%cd \"/content/drive/My Drive/50.021 Artificial Intelligence Group Assignment\"\n",
    "\n",
    "import os\n",
    "assert os.path.exists(DATASET_PATH), \"[!] Dataset path does not exist. Please check the path.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ed292f2"
   },
   "source": [
    "## 2. Install Dependencies (Colab Only)\n",
    "Installs necessary libraries for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oru_6s1W0eUv"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "def is_running_in_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if is_running_in_colab():\n",
    "  %pip install lightning polars\n",
    "  %pip install icecream rich tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fd0bec5"
   },
   "source": [
    "## 3. Import Libraries\n",
    "Imports all required packages including PyTorch, Lightning, and data processing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWmRP4sR2RQQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import lightning as L\n",
    "from pathlib import Path\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torchvision.transforms import v2\n",
    "import cv2\n",
    "from torchmetrics import (\n",
    "    Accuracy,\n",
    "    F1Score,\n",
    "    AUROC,\n",
    "    ConfusionMatrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed7b70d1"
   },
   "source": [
    "## 4. Check GPU Availability\n",
    "Ensures that a GPU is available for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1743411945225,
     "user": {
      "displayName": "nat ang",
      "userId": "01830563404866135370"
     },
     "user_tz": -480
    },
    "id": "bpOBH7tb1ioT",
    "outputId": "20cd6952-0005-46f4-ff09-4b98130b2c4e"
   },
   "outputs": [],
   "source": [
    "print(\"GPU available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfb7c84b"
   },
   "source": [
    "## 5. Define Dataset Class\n",
    "Creates a PyTorch dataset class for loading and processing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bu4Dq1Al6O89"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe: pl.DataFrame, training=False):\n",
    "        super().__init__()\n",
    "        paths = dataframe['image_path'].to_numpy().squeeze()\n",
    "        self.image_path = np.array([\n",
    "            str(Path('preprocessed_garbage_classification_images') / Path(p).name)\n",
    "            for p in paths\n",
    "        ])\n",
    "        self.garbage_type = dataframe.select('label').to_numpy().squeeze()\n",
    "        self.garbage_to_idx = {garbage: i for i, garbage in enumerate(np.unique(self.garbage_type))}\n",
    "        self.training = training\n",
    "\n",
    "        self.train_transforms = v2.Compose([\n",
    "            v2.RandomHorizontalFlip(),\n",
    "            v2.RandomVerticalFlip(),\n",
    "            v2.RandomErasing(),\n",
    "        ])\n",
    "\n",
    "        self.transforms = v2.Compose([\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_path[idx]\n",
    "\n",
    "        try:\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            image = torch.from_numpy(image).float()\n",
    "\n",
    "            if image.dim() == 2:\n",
    "                image = image.unsqueeze(0)\n",
    "\n",
    "            if self.training:\n",
    "                image = self.train_transforms(image)\n",
    "\n",
    "            image = self.transforms(image)\n",
    "\n",
    "            garbage = self.garbage_to_idx[self.garbage_type[idx]]\n",
    "\n",
    "            return image, torch.tensor(garbage, dtype=torch.long)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoVCpjKL6O89"
   },
   "source": [
    "## Method 1: Modifying first convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dakF4ASlac2e"
   },
   "outputs": [],
   "source": [
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        # Load EfficientNetV2-S with pre-trained weights\n",
    "        self.model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
    "\n",
    "        # Modify the first convolution layer to accept 1-channel input\n",
    "        original_conv = self.model.features[0][0]\n",
    "        new_conv = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=original_conv.out_channels,\n",
    "            kernel_size=original_conv.kernel_size,\n",
    "            stride=original_conv.stride,\n",
    "            padding=original_conv.padding,\n",
    "            bias=original_conv.bias is not None\n",
    "        )\n",
    "\n",
    "        # Copy pre-trained weights (taking only the first channel)\n",
    "        with torch.no_grad():\n",
    "            new_conv.weight.data = original_conv.weight.data[:, :1, :, :]\n",
    "\n",
    "        self.model.features[0][0] = new_conv\n",
    "\n",
    "        # Modify the classifier layer for the number of classes\n",
    "        self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        return self.model(x)\n",
    "\n",
    "class GarbageClassificationData(L.LightningDataModule):\n",
    "    def __init__(self, ws_root: Path = Path(\".\"), num_workers=0):\n",
    "        super().__init__()\n",
    "        metadata_path = ws_root / 'preprocessed_garbage_classification_images' / 'metadata'\n",
    "        self.train_ds = ImageDataset(pl.read_csv(metadata_path / 'train.csv'), training=True)\n",
    "        self.val_ds = ImageDataset(pl.read_csv(metadata_path / 'validation.csv'))\n",
    "        self.test_ds = ImageDataset(pl.read_csv(metadata_path / 'test.csv'))\n",
    "\n",
    "        self.n_classes = len(self.train_ds.garbage_to_idx)\n",
    "        self.idx_to_garbage = {v: k for k, v in self.train_ds.garbage_to_idx.items()}\n",
    "\n",
    "        self.dataloader_extras = dict(\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=num_workers > 0\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_ds, batch_size=32, shuffle=True, **self.dataloader_extras)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_ds, batch_size=64, **self.dataloader_extras)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test_ds, batch_size=64, **self.dataloader_extras)\n",
    "\n",
    "class LitEfficientNetV2(L.LightningModule):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.model = EfficientNetModel(n_classes)\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Initialize metrics\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.test_f1 = F1Score(task=\"multiclass\", num_classes=n_classes, average='macro')\n",
    "        self.test_auroc = AUROC(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.test_confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=n_classes)\n",
    "\n",
    "        # Store metrics for final reporting\n",
    "        self.test_outputs = []\n",
    "\n",
    "        # Save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_pred, y)\n",
    "\n",
    "        # Log training loss\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_pred, y)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = (y_pred.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        # Log validation metrics\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_accuracy', accuracy, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "\n",
    "        # Softmax probabilities for AUROC\n",
    "        y_pred_proba = torch.nn.functional.softmax(y_pred, dim=1)\n",
    "\n",
    "        # Compute metrics\n",
    "        self.test_accuracy(y_pred.argmax(dim=1), y)\n",
    "        self.test_f1(y_pred.argmax(dim=1), y)\n",
    "        self.test_auroc(y_pred_proba, y)\n",
    "        self.test_confusion_matrix(y_pred.argmax(dim=1), y)\n",
    "\n",
    "        # Store outputs for potential later analysis\n",
    "        self.test_outputs.append({\n",
    "            'y_pred': y_pred,\n",
    "            'y_true': y\n",
    "        })\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Compute and log final metrics\n",
    "        accuracy = self.test_accuracy.compute()\n",
    "        f1_score = self.test_f1.compute()\n",
    "        auroc = self.test_auroc.compute()\n",
    "        conf_mat = self.test_confusion_matrix.compute().cpu().numpy()\n",
    "\n",
    "        # Print detailed metrics\n",
    "        print(\"\\n--- Test Metrics ---\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Macro F1 Score: {f1_score:.4f}\")\n",
    "        print(f\"AUROC: {auroc:.4f}\")\n",
    "\n",
    "        # Visualize Confusion Matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Test Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Optional: Log metrics to TensorBoard if needed\n",
    "        self.log('test_accuracy', accuracy)\n",
    "        self.log('test_f1_score', f1_score)\n",
    "        self.log('test_auroc', auroc)\n",
    "\n",
    "        # Reset metrics\n",
    "        self.test_accuracy.reset()\n",
    "        self.test_f1.reset()\n",
    "        self.test_auroc.reset()\n",
    "        self.test_confusion_matrix.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798,
     "referenced_widgets": [
      "d97169d22a4d4fa788cd0d6d1b974bdf",
      "538ad5c48b8141d9a570746f999c7228",
      "ffc3b36996ac4775be869eaa2934f2f3",
      "10f76972c2c3438ca473ff1bf3cc2293",
      "5e769f54e980470d8d5a7363a134acfb",
      "3754a8dbe60a40d98a8404d94bae3f01",
      "d64529a4940b47deb8ad171c0a30c1d4",
      "aa55b5dcd7ea41558d328f5d822461f9",
      "fada4e0fe3c741e8be2173ece04858e9",
      "2b3e9614b4094a3485bf41053d4aa186",
      "2342add1fcf043049df638fc1424263e",
      "1b2fc6481ca04f0880e43064d9e10c8f",
      "d936e138b98147788c34a9f3c2472cef",
      "7ec806d1c0244090a5d23ba1d23db3f4",
      "187207beed994858b1797dc5d159225f",
      "377e24d0fb06497193dca359898fa7fb",
      "d413897f0066447cabd1f0e9cfa467ba",
      "3b584f21cf914be292e08fe1931af8d0",
      "536cd625b67c4c5d853a1808da017a2f",
      "c82c980c34914bdb9932755ed61e53e8",
      "b1b59103497e44ed84332a1a6a76883e",
      "d354d6c83a3349d3bf5d0a8df24b049e",
      "7e77e3be59dd49398e661928bec58e5b",
      "079dfe9f481f4712a7959b658082194b",
      "06d7810edbc14722ae1b57e1ed552a49",
      "b4637dc2d90c4bab82c092ebe6fdf939",
      "0d597bd1577f442eb5a3b95d259970b5",
      "d395eb0f1946499888d2dc0628ca084d",
      "b5f1743ba97b4d8b89bb98613250387a",
      "24a0d3afbb624d578f1b0fa5377d0fd3",
      "788e9832e6754041b4a85310b5484a38",
      "139d3e802460468786d079eef3587c7b",
      "39c318ecaf694c09937afd4517ec83f8",
      "cd3ecdfa8de041b396ef3d02624a6c67",
      "993da2517a194f9b9a89a6c44425e786",
      "fdc44462bd9e42aa9e685233bb6ee330",
      "7022b50d16e84c6fb4e7334570a949a3",
      "69edb12296df43d5b7b7fc0983347895",
      "ff6478f0a4134d3391b07518df09f9e6",
      "b7ea218fc4014a458df1473ff56ddc1e",
      "7fa744b3021443208e49678571e629bc",
      "3917264932f14f78a806f46c54e44a79",
      "df69269eb3444cd0a19ade34b3f41683",
      "f6fb94c8d60f4a4c9eaae32fc65f7238",
      "087f990779ce47f99bc6f23cea3955a5",
      "f40088eb5cb5491d9f75ad7ef3f7ec37",
      "8094168e9b6f4da2aaa65ca1dcd0f69b",
      "dffae2f7bfc148708aec080621a8c80e",
      "eee91ba9b48f4c0999a1100b4e2e5705",
      "f0f9ca81168b40e5ad63ac51930bfa7a",
      "dd757a8e7efc49ee8fcb97c8c024695f",
      "c981994c9b3842bf98d6bb73d2bc2db6",
      "4342781bc9d94c4984ebd7d9888f5dac",
      "426f5b31857e40b8a462436d1e17601a",
      "83bcf61a03394334ae058a6c4d999e39",
      "b01634d75a9b4b5780e6e90d114b8d6e",
      "57523720464040e7bd2e58e42c60ffb0",
      "7492de7f35f84ab2a15b65db0224a859",
      "343e463f78614bf3b1b0ce794f92a60a",
      "cccaf5a810ce4f0294a1f2c10be9a9f2",
      "d1b322c4fd7e4c61bc1cb663628fe2c8",
      "1183b08def274b0ab03f3108ec521ae9",
      "f86cc391532a45ff8f0415864bb75b2b",
      "2296d35203084f288598fc390235cada",
      "f02bfdbfa8af4f739628f0298e25d2cb",
      "453a20a8979145699d1b50c85b46140b",
      "f1a85fa052a0451e8c3243dd27c762b5",
      "61c95478ff4a4889b44b3ecc7583c0f3",
      "7706299630c74c5c9417e0b6bb11e78b",
      "5943d078e57a46b6aa51dfa6d5160ef0",
      "435cf2afcac04c1a8fe0cea31defd5a3",
      "11ff5367af8d4065a4ce1096f6562f0e",
      "2bb1c2e5ea6641bba19b213c92eeecd3",
      "4fd10596b334468599eb52c77a6113fe",
      "b95e1f4e7fb54ab4b6bbce8fc0494d62",
      "94cdc4d157f5462d86ee453e3db221ec",
      "65d9872a65a04d8599de6adb5995d553",
      "79f7a16d45ca4fbab82bccfb05adca13",
      "3881fe32013643a8a97e054a92ecd4c1",
      "74b702044ce8469a83d10a833e72ddd6",
      "2a54f0ca41844221b8836a0237e2fb0e",
      "7d258000b89e40438b312229ae9bf377",
      "a1295e71ee864aff8f44d36bbdb94c08",
      "548e3af99fb5438e8032112c18b3e18d",
      "3741aa54e7734b48b67b088697133dd5",
      "4e2634e1ecb04c448baaf8cdd8e8f9f2",
      "8186fd5f9ebb4e29a4fb3fa2b138be96",
      "c2e383d798d34414bebb9a6de0ce2d72",
      "8ebd9ea7d01240cc8ed19ae0d0a43b82",
      "5195dd5efcdc4e0ca0254fa69b01df4c",
      "2725fc040e0a4591b7010b726bbf1c00",
      "f1406084b6a048158d0861d9f254d34a",
      "9014bf2ef1ba42fe8d0489ff61499912",
      "c2b9026697ee40049cf4f735a3db2ceb",
      "cf48ba1efd39465ba519011782fdaf35",
      "b3e19f30b9fd4226b30c0253992e3200",
      "8b4f06a682684635b520312f2661e048",
      "a1165aa24df44045a5e634d8f4b2b1ef",
      "3801539cb26e47b6aea8a715e3067427",
      "277977e721924139a64a7e915d0c1fb8",
      "52b38b3a03184c85ad9cc0b75454afe7",
      "eeb131f6f1eb4116a94eb0fd33a984e3",
      "96dc5e3042ab433985543a253d167488",
      "166b12adb2574908bd7825c8dabfd9ad",
      "770d91ab96ab4df3bec07979b44a9d34",
      "1b99f3d553b44f679560779f9019c849",
      "1c34a0d78d024cbdac78614eccfde01d",
      "55a3280a8651429fb88054f42b2f6c6a",
      "b2f7e12db367405f8837485724793a5f",
      "87b470921437478c9e735b62e7d6a980",
      "1b6fa2fb6b094609b4de85668688b0f1",
      "74f36c7825da481f99f874ec17450f18",
      "fec5ffe2c6e5435d9f09953f81b1cbe0",
      "819ff5cd039b49e8b474fc2e09b7db53",
      "cca2636f5eba438ba5d26d0bc90e53c1",
      "ddc3bfe38ef54cd1b702ef944ddc9fcb",
      "3c9383717eca4e3c9d3db6847c453fe4",
      "5aae737b7f71484c904fc7c0ce0f27d7",
      "804c9b3464a1435fb27a2c850115a53c",
      "c75f42b4febd49238fd0eea33cdb7d5b",
      "1c6e6650f5d9439f9b92f1e31652bb99",
      "f52ac8c19b8b493d8f61e6212307317b",
      "14d38dacab0142fabb48426550fd5fb3",
      "0493329a6a974cccbe790a25a5bf76a5",
      "89707a59398b4799bc03689c058a615e",
      "5370508e5c234145bfd724dd704bcab6",
      "958e0448813b46acae37ff7a340d1b8f",
      "29e82b024ee8460981d4f94f699145ed",
      "f76dfd5670f5484ca9ceef53a30e5b35",
      "a0b391229f7c4047a3c1045ae2b10f46",
      "da611b8dd10f41d892ed2cc8849db98a",
      "cdf401fb004343c5ae8af76c37cefd53"
     ]
    },
    "executionInfo": {
     "elapsed": 1699647,
     "status": "ok",
     "timestamp": 1743220894858,
     "user": {
      "displayName": "nat ang",
      "userId": "01830563404866135370"
     },
     "user_tz": -480
    },
    "id": "_RJXzF8Y7Z6b",
    "outputId": "eeb5f079-df5f-4ba9-cf92-a844da5c47f3"
   },
   "outputs": [],
   "source": [
    "# Rest of the code remains the same as in the previous example\n",
    "# Set up checkpoint directory\n",
    "checkpoint_dir = Path('checkpoints/efficientnetv2')\n",
    "print(checkpoint_dir.resolve())  # Print absolute path\n",
    "\n",
    "# Create checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=str(checkpoint_dir),\n",
    "    filename='garbage-classification-{epoch:02d}-{val_accuracy:.2f}',\n",
    "    save_top_k=3,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# Prepare data\n",
    "garbage_classification_data = GarbageClassificationData(num_workers=4)\n",
    "\n",
    "# Check for existing checkpoints\n",
    "checkpoints = list(checkpoint_dir.glob('*.ckpt'))\n",
    "\n",
    "# Set up trainer with TensorBoard logger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='logs', name='efficientnetv2')\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='gpu',\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Load from latest checkpoint or start fresh\n",
    "if checkpoints:\n",
    "    latest_checkpoint = max(checkpoints, key=lambda x: x.stat().st_mtime)\n",
    "    print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n",
    "    lit_model = LitEfficientNetV2.load_from_checkpoint(\n",
    "        str(latest_checkpoint),\n",
    "        n_classes=garbage_classification_data.n_classes\n",
    "    )\n",
    "else:\n",
    "    print(\"Starting fresh training...\")\n",
    "    lit_model = LitEfficientNetV2(garbage_classification_data.n_classes)\n",
    "\n",
    "# Start training\n",
    "trainer.fit(model=lit_model, datamodule=garbage_classification_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7_Te3bo7dT1"
   },
   "source": [
    "### Method 1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f4aef13848df4e94b85a43e358b62dfb",
      "b12518a79bdf49c3a026c5743a8b172d",
      "c38ba2094f87454f9d3b6837c9fb1c79",
      "ec198f11b1ca4446a1e72e200e7ab54a",
      "39b10dc6ae4b4803ba1ee744812e8233",
      "050a2b54160743ee8a57c2d4e1707147",
      "f86489a46a3a46b7afa2a331979d360c",
      "0a8db85716004ffea4a86c8e290ab6f2",
      "5b4fcf3979954c6db4ff840b1afe23f9",
      "3a0ffd3b23aa45ff9fd26bc5d68b8e4c",
      "79b729d73a2b43158367c7c3867b2305"
     ]
    },
    "executionInfo": {
     "elapsed": 246393,
     "status": "ok",
     "timestamp": 1743221141255,
     "user": {
      "displayName": "nat ang",
      "userId": "01830563404866135370"
     },
     "user_tz": -480
    },
    "id": "M_Ji-RcS7fwF",
    "outputId": "f817dee5-99f7-4978-f5a1-06f31e1dbe4d"
   },
   "outputs": [],
   "source": [
    "trainer.test(model=lit_model, datamodule=garbage_classification_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqXh4-dybkFa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8ivoHfPbjrE"
   },
   "source": [
    "## Method 2: Fine Tuning\n",
    "Key changes:\n",
    "- Freezing of 5 early layers to preserve feature extractors, only updating task-specific layers.\n",
    "- Use a more sophisticated classifier head - 512, ReLU activation\n",
    "- Regularization: use 0.3 dropout to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xg5HmsnfeEvA"
   },
   "outputs": [],
   "source": [
    "class GarbageClassificationData(L.LightningDataModule):\n",
    "    def __init__(self, ws_root: Path = Path(\".\"), num_workers=0):\n",
    "        super().__init__()\n",
    "        metadata_path = ws_root / 'preprocessed_garbage_classification_images' / 'metadata'\n",
    "        self.train_ds = ImageDataset(pl.read_csv(metadata_path / 'train.csv'), training=True)\n",
    "        self.val_ds = ImageDataset(pl.read_csv(metadata_path / 'validation.csv'))\n",
    "        self.test_ds = ImageDataset(pl.read_csv(metadata_path / 'test.csv'))\n",
    "\n",
    "        self.n_classes = len(self.train_ds.garbage_to_idx)\n",
    "        self.idx_to_garbage = {v: k for k, v in self.train_ds.garbage_to_idx.items()}\n",
    "\n",
    "        self.dataloader_extras = dict(\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=num_workers > 0\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_ds, batch_size=32, shuffle=True, **self.dataloader_extras)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_ds, batch_size=64, **self.dataloader_extras)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test_ds, batch_size=64, **self.dataloader_extras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvx_pmZFb-dT"
   },
   "outputs": [],
   "source": [
    "class EfficientNetV2FineTuned(L.LightningModule):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning model that fine-tunes EfficientNetV2-S for custom image classification.\n",
    "\n",
    "    Key Features:\n",
    "    - Freezes the early layers to retain pre-trained features.\n",
    "    - Replaces the classifier head with a custom MLP.\n",
    "    - Uses transfer learning for improved generalization.\n",
    "\n",
    "    Attributes:\n",
    "        model (torchvision.models.EfficientNet): Pre-trained EfficientNetV2-S model.\n",
    "        num_classes (int): Number of output classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int):\n",
    "        \"\"\"\n",
    "        Initializes the fine-tuned EfficientNetV2-S model.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of classes in the dataset.\n",
    "        \"\"\"\n",
    "        super(EfficientNetV2FineTuned, self).__init__()\n",
    "\n",
    "        # Load pre-trained EfficientNetV2-S model\n",
    "        self.model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
    "\n",
    "        # Freeze early layers (first 5 blocks of EfficientNet)\n",
    "        for param in self.model.features[:5].parameters():\n",
    "            param.requires_grad = False  # Stop gradients in early layers\n",
    "\n",
    "        # Modify the first convolutional layer to accept grayscale input (1 channel)\n",
    "        self.model.features[0][0] = nn.Conv2d(\n",
    "            in_channels=1,  # Grayscale input\n",
    "            out_channels=self.model.features[0][0].out_channels,\n",
    "            kernel_size=self.model.features[0][0].kernel_size,\n",
    "            stride=self.model.features[0][0].stride,\n",
    "            padding=self.model.features[0][0].padding,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        # Modify the classifier head (fully connected layers)\n",
    "        in_features = self.model.classifier[1].in_features  # Get input size of the classifier\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),  # Add an intermediate hidden layer\n",
    "            nn.ReLU(),  # Activation function\n",
    "            nn.Dropout(0.3),  # Dropout for regularization\n",
    "            nn.Linear(512, num_classes)  # Final output layer\n",
    "        )\n",
    "\n",
    "        # Loss function (CrossEntropyLoss for classification)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Initialize metrics for testing\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_f1 = F1Score(task=\"multiclass\", num_classes=num_classes, average='macro')\n",
    "        self.test_auroc = AUROC(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "        # Save number of classes for later use\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 1, 224, 224).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Model output logits.\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training step: Computes loss for a batch.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): (images, labels).\n",
    "            batch_idx (int): Batch index.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Training loss.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step for monitoring model performance during training.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): (images, labels).\n",
    "            batch_idx (int): Batch index.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing validation loss and accuracy.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(y_pred, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_accuracy', acc, prog_bar=True)\n",
    "\n",
    "        return {'val_loss': loss, 'val_accuracy': acc}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Test step for evaluating model on the test dataset.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): (images, labels).\n",
    "            batch_idx (int): Batch index.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing test metrics.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "\n",
    "        # Calculate predictions\n",
    "        preds = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        # Update metrics\n",
    "        self.test_accuracy(preds, y)\n",
    "        self.test_f1(preds, y)\n",
    "        self.test_auroc(torch.softmax(y_pred, dim=1), y)\n",
    "        self.test_confusion_matrix(preds, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('test_loss', loss, on_epoch=True)\n",
    "        self.log('test_accuracy', self.test_accuracy, on_epoch=True)\n",
    "        self.log('test_f1', self.test_f1, on_epoch=True)\n",
    "        self.log('test_auroc', self.test_auroc, on_epoch=True)\n",
    "\n",
    "        return {'test_loss': loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Called at the end of the test epoch to display and log final metrics.\n",
    "        \"\"\"\n",
    "        # Compute and log final metrics\n",
    "        acc = self.test_accuracy.compute()\n",
    "        f1 = self.test_f1.compute()\n",
    "        auroc = self.test_auroc.compute()\n",
    "        conf_mat = self.test_confusion_matrix.compute().cpu().numpy()\n",
    "\n",
    "        # Print detailed metrics\n",
    "        print(\"\\n--- Test Metrics ---\")\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(f\"Macro F1 Score: {f1:.4f}\")\n",
    "        print(f\"AUROC: {auroc:.4f}\")\n",
    "\n",
    "        # Visualize Confusion Matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Test Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configure the optimizer for training.\n",
    "\n",
    "        Returns:\n",
    "            torch.optim.Optimizer: The optimizer to use for training.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816,
     "referenced_widgets": [
      "b3d2ff6f3b354066b849f179577028d2",
      "c212c5bff80b4da398d4e155e4aeb459",
      "2fa67d934c4347c8bc648393c55bce59",
      "39113e3fbeff48fda9abc0f26f5fd616",
      "c03d3d53cd084442b16f61b75da1155c",
      "d5a11c063e6c41a29f0f61e172698d4e",
      "8f1c23bc532c40f990d4fc02a41d01ad",
      "92813a0d786949f88af71f86b5bd0151",
      "9b24e0cb0c0d464daedda7caa4a62c84",
      "b6e17d59f93447bca1ebe9175f9e2326",
      "1e90bbf15b6e4673ad93df726e6d5229",
      "cd31d2f721064739ab50d4b6e45358f4",
      "70b2dafdacab4615ac8603cea0a8035c",
      "46e7c32b80294746b4200f48971de7d3",
      "40585a66188b48a5823524efd2743587",
      "def950d574634d3499ae5bc5580f7b9d",
      "7583e321c7c34e85902fe25623c9cbde",
      "a08a194b5850412abe25cb6f35643f26",
      "e5f7ebcfc90441cc90aeb7b7d4ad879a",
      "f3cdefbd4c234a0384b26130334d682f",
      "9af22a8426da4953be4d12388709a867",
      "4fb8bb989795421987f3c5a357cf4331",
      "a1ea23e1560e40908a91f15de40d576a",
      "08ba92eabefb4ad5a603a456f636f746",
      "311998d2ea6a417e8a48f7d6eaf64577",
      "c6875788c2b1401283c4817a77d0197e",
      "0fba4622f66c42da882d6a66fb143cfa",
      "1dcdeb0cb2d44e7682a565a23926c56a",
      "52d2e1f14c0f4c0c8b1eb6518b52a17a",
      "677edd7fcb4c4c42bfa20d09e8ba1339",
      "5094442ec1b442138e8828fd5f8968ca",
      "cea9bcccb23443b39d61de0399a3e4e0",
      "ced4303541e94d53965900ca8694b07e",
      "aa8808a1adc0402d848a4ddf31f2098e",
      "48db44926a9b40978bc2579fc31a5f51",
      "34ff379ff7854b2990b96b05e57f0076",
      "73f5f34517314b4891b01709ae7aa139",
      "d1bcf9a3b37d408989891ebfa1ef6745",
      "2e5546225e084908af70877883620a66",
      "0ca99264030e46b585cbb26f6b9d2f13",
      "7195dea16e7f4d48a4ef469a4b917ccc",
      "f56737d13e31487081fe1942f4407936",
      "8654e9f4d4bd4178ad40d986b2bf326f",
      "c79f73360eb04f3f8e27b28db55a685e",
      "a999f39da96c42d9ad97a0a0fbf4d385",
      "0c90ca0218e84fbcb5438b007366fd1b",
      "f196a978fd154e2487f4802c3e20012f",
      "5d94010efcc247408a42b8c0b70eee72",
      "bacdbe9cb5bb4602be9522c9ed15d2f0",
      "ed7a03206e2d410481c4b1f68ab041e6",
      "9b9e7a9df753491986019a0ae4d4f7d1",
      "7227c08e97954298af0ddfdf947cd125",
      "d4156a53a18e4420a3843a615477e50e",
      "6d5046a80aa6470ca0bbb4744f5b07ba",
      "7c14416304db442b9439a307e41fdbb3",
      "460d6efb92ac4c71b2888ddb910d7cd3",
      "fe857714c158480388d0992acc9899fd",
      "3384f0f721714f2aab9c1d810a59a442",
      "cc984b14025c436d89ae3134d64dff6e",
      "9bcacfe787f54a1285e9f8120c9ca293",
      "8a237f5afa8f4a7f8a1c99e2ae68cf95",
      "871fea5201f74982bfa61e053faf16ad",
      "15d41e3082ad49268892bb84eab76218",
      "d4b5991599734775a4a6f24366819ce0",
      "f7ae7d8b417f44079f6b41109dda560f",
      "a9e44467b3ba41e299bb264eaf7fd544",
      "737302f7f62d42cb997e70d2c5ec2559",
      "c8f26a3c71454cea9331679c31c70ab1",
      "263f2eeecdac4b51ad56461751e316cf",
      "d965fd93fd2a459ca759e917e4b1df1a",
      "9ce7b108bbd947f9950b4e9ab8be25f7",
      "f54381be25ce4669825f39cf49e27788",
      "a31639ebb37c4995b2c770ed33e1bd7a",
      "fc84da6ef8fa4539920b860b8254bfa1",
      "9b0f169036564aef9b9b5f19b2a3f133",
      "02633822410e436ba6078a282993a20e",
      "bedf7b6caee847f793bd45dc612b84c4",
      "f8f8c7bf5aec41c38b12dfa450f899e2",
      "e465e87831d54cdb949e7081c472bccc",
      "294fb3ceed354292ac79038ea6e377ff",
      "237a2bc2d39540aeb5e796ff0cd34b0a",
      "598132339a54430daa039686adf9558d",
      "41720dfb428d4132a00303056b00630b",
      "f721591aa0ab4d719e7058ca88a4d3f5",
      "339159947fa34370a67d3bc5cf5a540a",
      "f97d64302e0e4b158bad0970be02f2b0",
      "48ec8f660c8848d49e838f8fec42db37",
      "dba2819d542c4e1c9b286358ce3fbc3b",
      "e9628629df174bd5adad8d5edc47dea9",
      "a68ed2309d6e4c14ae793f684e8635f1",
      "a4a12167422c478b83890cc7798c75f7",
      "5cd7fb5ec1694c5ea4cc8e7e64019d08",
      "a8a36e5842ec4454b29680c282242d35",
      "fc3d9e0b1f8742278dfac3fa758c5eca",
      "271274d1794e4d3ca990d22ab10a2c6e",
      "1efec767941f44dda5d399ce7d8d7307",
      "100efb9c7f3e4dfba5c2de2fb2979751",
      "9767b53a0d674407b871e583c252fbed",
      "88f97321d5b24475b6a3fd4a23384504",
      "93e689303e8f4289930347b0d995ccc4",
      "e0d815663f65459db18fba0f5ad45247",
      "5ac83dd0c4e444aea261e2e2e66cf604",
      "d9c428cc00ab4f9fae415661641f7e22",
      "9b1e2408bcda415dab27c63e39dc481c",
      "b1c3479742a942678f3052c33256dbcf",
      "9681c384dea34d2b8746308b55c925f0",
      "517fd9880eb24559992280b6138ed036",
      "2d7ee130261042b0a8cb5ccbfe2aa0e7",
      "fe7dd01879664d4fb93b71350452773d",
      "bf07b81e057c400fac37d483851a45ef",
      "ac33c93e90494da78c5c57888acbb909",
      "55e75ad4640d413c83a6067744c81e2c",
      "9522c8237d4447d8b490e4462f5dbe5e",
      "916dea83f04e46b395b8222e91e47fdd",
      "bbcfec3ecced4de78331bc0b942f0013",
      "3e30db7359f548de86e8db47f674a2dc",
      "cd0604954b35410dbd187b1f4103dacf",
      "9a59b2f696b2435a9b37968d6498e0b3",
      "da3d5bd930cf41b590baaa47b0b6dad2",
      "ba164aeec72046e6bbd6c7a466945dbc",
      "6296f2d0cbd3402ebcbbb4d3cc05622a",
      "573c94debe5544439719b6664668311d",
      "ad9f7a9943444db09d85f99413b107c4",
      "50795404f4e649b29f0570db8d7d9a67",
      "f16b14faa60c46aab7c7c28c4dd1a55d",
      "3148b4d72360472ca0113fef9c65159e",
      "490cf1351ce0456ca107bc08ebb59b5b",
      "09acc9fb8f734207aacd24c1a12ccc2c",
      "90d2f67b0fba4d2981dc7c6223f7f2da",
      "272edfe6b98642e68521381b55d3d8f1",
      "f27364f87212451583d60c2d49bc3bbe",
      "a1f777285088499097092fe74e8bbfe5"
     ]
    },
    "executionInfo": {
     "elapsed": 752185,
     "status": "ok",
     "timestamp": 1743415441785,
     "user": {
      "displayName": "nat ang",
      "userId": "01830563404866135370"
     },
     "user_tz": -480
    },
    "id": "tC2fDaXanN0r",
    "outputId": "98c4245c-a038-4895-cf41-506873c430fa"
   },
   "outputs": [],
   "source": [
    "# Set up checkpoint directory\n",
    "checkpoint_dir = Path('checkpoints/efficientnetv2finetuned')\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "print(f\"Checkpoint directory: {checkpoint_dir.resolve()}\")\n",
    "\n",
    "# Create checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=str(checkpoint_dir),\n",
    "    filename='garbage-classification-{epoch:02d}-{val_accuracy:.2f}',\n",
    "    save_top_k=3,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# Prepare dataset\n",
    "garbage_classification_data = GarbageClassificationData(num_workers=4)\n",
    "\n",
    "# Check for existing checkpoints\n",
    "checkpoints = list(checkpoint_dir.glob('*.ckpt'))\n",
    "\n",
    "# Set up TensorBoard logger\n",
    "logger = TensorBoardLogger(save_dir='logs', name='efficientnetv2finetuned')\n",
    "\n",
    "# Initialize PyTorch Lightning Trainer\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',  # Auto GPU detection\n",
    "    precision=\"16-mixed\",\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Load from latest checkpoint or start fresh\n",
    "if checkpoints:\n",
    "    latest_checkpoint = max(checkpoints, key=lambda x: x.stat().st_mtime)\n",
    "    print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n",
    "    model2 = EfficientNetV2FineTuned.load_from_checkpoint(\n",
    "        checkpoint_path=str(latest_checkpoint),\n",
    "        num_classes=garbage_classification_data.n_classes\n",
    "    )\n",
    "else:\n",
    "    print(\"Starting fresh training...\")\n",
    "    model2 = EfficientNetV2FineTuned(num_classes=garbage_classification_data.n_classes)\n",
    "\n",
    "# Start training\n",
    "trainer.fit(model=model2, datamodule=garbage_classification_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWQbd7UHqnqQ"
   },
   "source": [
    "### Method 2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6b8db521bab24da4a6fdeeaaf5bb5f0d",
      "88bb560e25cb4cb9b6981cfe07bcf876",
      "3fb7fe9730b04208b4c262c9951a53fd",
      "c9c37b8805e246bf978c608183048069",
      "18261cc04aaa4ca3bbf201587ca99be9",
      "0f915469695040b4975943eb814e5cee",
      "fd63bf44f57040799c44cd7833859b4b",
      "3029d81987c543538fabf2304a2ef5ee",
      "4a851f072a0f41ad8194568e5689b46e",
      "6d8e969537f64dc194d3f3a0c0342502",
      "269246d18a054e28accc7e5b0275f0bb"
     ]
    },
    "executionInfo": {
     "elapsed": 251682,
     "status": "ok",
     "timestamp": 1743415693521,
     "user": {
      "displayName": "nat ang",
      "userId": "01830563404866135370"
     },
     "user_tz": -480
    },
    "id": "2WRVfTcicCz4",
    "outputId": "4d49569d-74a6-4bdb-fe3b-e4a79d3ed152"
   },
   "outputs": [],
   "source": [
    "trainer.test(model=model2, datamodule=garbage_classification_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXD94sjblMUp"
   },
   "outputs": [],
   "source": [
    "torch.save(model2, \"efficientnetv2-finetuned.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bA_GcdbLtu_-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG0YdLKt6O8-"
   },
   "source": [
    "## Comparison / Analysis\n",
    "\n",
    "### Method 1 Results:\n",
    "Accuracy: 0.7110\n",
    "\n",
    "Macro F1 Score: 0.7066\n",
    "\n",
    "AUROC: 0.9530"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTZaJk8mreuY"
   },
   "source": [
    "### Method 2 Results:\n",
    "Accuracy: 0.7284\n",
    "\n",
    "Macro F1 Score: 0.7163\n",
    "\n",
    "AUROC: 0.9523"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Shg7SLEErc4o"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Method 2 has slightly better test accuracy and F1 score, but not much of an improvement is seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4xveBtfqLir"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
