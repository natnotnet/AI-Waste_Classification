{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixrKHXr98hxS"
   },
   "source": [
    "# Best Model Analysis\n",
    "This notebook prints the confusion matrix for our best performing model (MobileNet Version 6) for more in depth performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0weFfY928fk3",
    "outputId": "6932dc7c-6c78-44a2-b5db-284019a0f60c"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DATASET_PATH = '/content/drive/My Drive/50.021 Artificial Intelligence Group Assignment'\n",
    "\n",
    "%cd \"/content/drive/My Drive/50.021 Artificial Intelligence Group Assignment\"\n",
    "\n",
    "import os\n",
    "assert os.path.exists(DATASET_PATH), \"[!] Dataset path does not exist. Please check the path.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lU3_BNs78sZe"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "def is_running_in_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if is_running_in_colab():\n",
    "  %pip install lightning polars\n",
    "  %pip install icecream rich tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qlFTZW-8sWW"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import lightning as L\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "# Model imports\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Metrics imports\n",
    "from torchmetrics import (\n",
    "    Accuracy,\n",
    "    F1Score,\n",
    "    AUROC,\n",
    "    ConfusionMatrix,\n",
    "    Precision,\n",
    "    Recall\n",
    ")\n",
    "\n",
    "# Lightning modules and callbacks\n",
    "from lightning.pytorch.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor\n",
    ")\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUUoijIu-egt"
   },
   "source": [
    "## Copy over relevant classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkTYwm8o-g3x"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset for loading and preprocessing garbage classification images.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe: pl.DataFrame, training=False, img_size=224):\n",
    "        super().__init__()\n",
    "        # Use the image_path column directly from the dataframe as it now contains full paths\n",
    "        # to the preprocessed RGB images\n",
    "        self.image_path = dataframe['image_path'].to_numpy().squeeze()\n",
    "        self.garbage_type = dataframe.select('label').to_numpy().squeeze()\n",
    "        self.garbage_to_idx = {garbage: i for i, garbage in enumerate(np.unique(self.garbage_type))}\n",
    "        self.training = training\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # Enhanced augmentation for training - can be simpler now since images are already preprocessed\n",
    "        self.train_transforms = v2.Compose([\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "            v2.RandomVerticalFlip(p=0.3),\n",
    "            v2.RandomRotation(degrees=10),\n",
    "            # Reduced augmentation as images are already preprocessed and augmented\n",
    "        ])\n",
    "\n",
    "        # Base transforms for all images\n",
    "        self.transforms = v2.Compose([\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_path[idx]\n",
    "\n",
    "        try:\n",
    "            # Load the image - now these are RGB processed images\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Failed to load image at {image_path}\")\n",
    "\n",
    "            # Convert BGR to RGB (cv2 loads as BGR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Resize to the target size\n",
    "            image = cv2.resize(image, (self.img_size, self.img_size))\n",
    "\n",
    "            # Convert to tensor and reorder dimensions to [C, H, W]\n",
    "            image = torch.from_numpy(image).float().permute(2, 0, 1)\n",
    "\n",
    "            # Normalize to [0, 1]\n",
    "            image = image / 255.0\n",
    "\n",
    "            # Apply augmentations if in training mode\n",
    "            if self.training:\n",
    "                image = self.train_transforms(image)\n",
    "\n",
    "            # Apply basic transforms\n",
    "            image = self.transforms(image)\n",
    "\n",
    "            # Get class label\n",
    "            garbage = self.garbage_to_idx[self.garbage_type[idx]]\n",
    "\n",
    "            return image, torch.tensor(garbage, dtype=torch.long)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8ilH7x--ixg"
   },
   "outputs": [],
   "source": [
    "class GarbageClassificationData(L.LightningDataModule):\n",
    "    \"\"\"Data module for garbage classification dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, ws_root: Path = Path(\".\"), batch_size=32, num_workers=0, img_size=224):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # Updated paths to use the new RGB preprocessed images\n",
    "        rgb_base_path = Path(\"/content/drive/My Drive/50.021 Artificial Intelligence Group Assignment/RGB_preprocessed_images\")\n",
    "\n",
    "        # Load datasets using the new CSV files\n",
    "        self.train_ds = ImageDataset(\n",
    "            pl.read_csv(rgb_base_path / 'train.csv'),\n",
    "            training=True,\n",
    "            img_size=self.img_size\n",
    "        )\n",
    "        self.val_ds = ImageDataset(\n",
    "            pl.read_csv(rgb_base_path / 'validation.csv'),\n",
    "            img_size=self.img_size\n",
    "        )\n",
    "        self.test_ds = ImageDataset(\n",
    "            pl.read_csv(rgb_base_path / 'test.csv'),\n",
    "            img_size=self.img_size\n",
    "        )\n",
    "\n",
    "        # Get class info\n",
    "        self.n_classes = len(self.train_ds.garbage_to_idx)\n",
    "        self.idx_to_garbage = {v: k for k, v in self.train_ds.garbage_to_idx.items()}\n",
    "\n",
    "        # Print dataset statistics\n",
    "        print(f\"Number of training samples: {len(self.train_ds)}\")\n",
    "        print(f\"Number of validation samples: {len(self.val_ds)}\")\n",
    "        print(f\"Number of test samples: {len(self.test_ds)}\")\n",
    "        print(f\"Number of classes: {self.n_classes}\")\n",
    "        print(f\"Classes: {self.idx_to_garbage}\")\n",
    "\n",
    "        # DataLoader settings\n",
    "        self.dataloader_extras = dict(\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=num_workers > 0\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            **self.dataloader_extras\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_ds,\n",
    "            batch_size=self.batch_size*2,\n",
    "            **self.dataloader_extras\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_ds,\n",
    "            batch_size=self.batch_size*2,\n",
    "            **self.dataloader_extras\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8Tw7BUY9kin"
   },
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLgKt943-AHs"
   },
   "outputs": [],
   "source": [
    "class MobileNetV2_6(L.LightningModule):\n",
    "\n",
    "    def __init__(self, n_classes, learning_rate=3e-4, weight_decay=1e-4):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.mixup_alpha = 0.2  # Parameter for mixup augmentation\n",
    "\n",
    "        # Load pre-trained MobileNetV2 model\n",
    "        self.model = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "\n",
    "        # Initialize frozen layer flags for progressive unfreezing\n",
    "        self.unfreeze_stage = 0\n",
    "\n",
    "        # Initially freeze all feature extraction layers\n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Get the number of features in the final layer\n",
    "        in_features = self.model.classifier[1].in_features\n",
    "\n",
    "        # Replace classifier with enhanced MLP head\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.4),  # Increased dropout rate\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),  # SiLU/Swish activation (better than ReLU)\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, n_classes)\n",
    "        )\n",
    "\n",
    "        # Use label smoothing cross entropy\n",
    "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "        # Initialize metrics\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "\n",
    "        # Test metrics\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.test_precision = Precision(task=\"multiclass\", num_classes=n_classes, average='macro')\n",
    "        self.test_recall = Recall(task=\"multiclass\", num_classes=n_classes, average='macro')\n",
    "        self.test_f1 = F1Score(task=\"multiclass\", num_classes=n_classes, average='macro')\n",
    "        self.test_auroc = AUROC(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.test_confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=n_classes)\n",
    "\n",
    "        # Save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def mixup_data(self, x, y):\n",
    "        \"\"\"Apply mixup augmentation to the batch.\"\"\"\n",
    "        if self.training and self.mixup_alpha > 0:\n",
    "            lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "            batch_size = x.size()[0]\n",
    "            index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "            mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "            y_a, y_b = y, y[index]\n",
    "            return mixed_x, y_a, y_b, lam\n",
    "        else:\n",
    "            return x, y, y, 1.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        # Apply mixup if training\n",
    "        if self.training:\n",
    "            x, y_a, y_b, lam = self.mixup_data(x, y)\n",
    "            y_pred = self(x)\n",
    "            loss = lam * self.criterion(y_pred, y_a) + (1 - lam) * self.criterion(y_pred, y_b)\n",
    "        else:\n",
    "            y_pred = self(x)\n",
    "            loss = self.criterion(y_pred, y)\n",
    "\n",
    "        # Calculate and log metrics\n",
    "        preds = torch.argmax(y_pred, dim=1)\n",
    "        acc = self.train_acc(preds, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "\n",
    "        # Calculate metrics\n",
    "        preds = torch.argmax(y_pred, dim=1)\n",
    "        acc = self.val_acc(preds, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "\n",
    "        # Calculate predictions\n",
    "        preds = torch.argmax(y_pred, dim=1)\n",
    "        probs = torch.softmax(y_pred, dim=1)\n",
    "\n",
    "        # Update metrics\n",
    "        self.test_accuracy(preds, y)\n",
    "        self.test_precision(preds, y)\n",
    "        self.test_recall(preds, y)\n",
    "        self.test_f1(preds, y)\n",
    "        self.test_auroc(probs, y)\n",
    "        self.test_confusion_matrix(preds, y)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('test_loss', loss, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Compute and log final metrics\n",
    "        accuracy = self.test_accuracy.compute()\n",
    "        precision = self.test_precision.compute()\n",
    "        recall = self.test_recall.compute()\n",
    "        f1_score = self.test_f1.compute()\n",
    "        auroc = self.test_auroc.compute()\n",
    "        conf_mat = self.test_confusion_matrix.compute().cpu().numpy()\n",
    "\n",
    "        # Store metrics in self for access after training\n",
    "        self.final_metrics = {\n",
    "            'accuracy': accuracy.item(),\n",
    "            'precision': precision.item(),\n",
    "            'recall': recall.item(),\n",
    "            'f1': f1_score.item(),\n",
    "            'auroc': auroc.item()\n",
    "        }\n",
    "\n",
    "        # Print detailed metrics\n",
    "        print(\"\\n--- Test Metrics ---\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1_score:.4f}\")\n",
    "        print(f\"AUROC: {auroc:.4f}\")\n",
    "\n",
    "        # Reset metrics\n",
    "        self.test_accuracy.reset()\n",
    "        self.test_precision.reset()\n",
    "        self.test_recall.reset()\n",
    "        self.test_f1.reset()\n",
    "        self.test_auroc.reset()\n",
    "        self.test_confusion_matrix.reset()\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        \"\"\"\n",
    "        Progressive unfreezing of layers based on training epoch.\n",
    "        \"\"\"\n",
    "        # Get total number of blocks in MobileNetV2 features\n",
    "        total_blocks = len(self.model.features)\n",
    "\n",
    "        if self.current_epoch == 3 and self.unfreeze_stage == 0:\n",
    "            # Unfreeze the last 30% of feature layers after 3 epochs\n",
    "            unfreeze_from = int(total_blocks * 0.7)\n",
    "            for i in range(unfreeze_from, total_blocks):\n",
    "                for param in self.model.features[i].parameters():\n",
    "                    param.requires_grad = True\n",
    "            print(f\"Unfreezing layers from {unfreeze_from} to {total_blocks-1}\")\n",
    "            self.unfreeze_stage = 1\n",
    "\n",
    "        elif self.current_epoch == 6 and self.unfreeze_stage == 1:\n",
    "            # Unfreeze more layers after 6 epochs\n",
    "            unfreeze_from = int(total_blocks * 0.4)\n",
    "            for i in range(unfreeze_from, total_blocks):\n",
    "                for param in self.model.features[i].parameters():\n",
    "                    param.requires_grad = True\n",
    "            print(f\"Unfreezing layers from {unfreeze_from} to {total_blocks-1}\")\n",
    "            self.unfreeze_stage = 2\n",
    "\n",
    "        elif self.current_epoch == 9 and self.unfreeze_stage == 2:\n",
    "            # Unfreeze all layers after 9 epochs\n",
    "            for i in range(total_blocks):\n",
    "                for param in self.model.features[i].parameters():\n",
    "                    param.requires_grad = True\n",
    "            print(\"Unfreezing all layers\")\n",
    "            self.unfreeze_stage = 3\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configure optimizer with weight decay and learning rate scheduler.\n",
    "        \"\"\"\n",
    "        # Create optimizer with weight decay\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "\n",
    "        # OneCycleLR scheduler\n",
    "        scheduler = {\n",
    "            \"scheduler\": OneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=self.learning_rate,\n",
    "                total_steps=self.trainer.estimated_stepping_batches,\n",
    "                pct_start=0.1,  # 10% warmup\n",
    "                div_factor=25,  # initial_lr = max_lr/25\n",
    "                final_div_factor=1000,  # min_lr = initial_lr/1000\n",
    "            ),\n",
    "            \"interval\": \"step\",\n",
    "            \"frequency\": 1\n",
    "        }\n",
    "\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sasTz41L8sT9",
    "outputId": "a710ea15-b6f2-40f2-8a9a-f02994dc17e2"
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7d5dgDp8sRd",
    "outputId": "319ea2a3-2fcd-412d-8819-ad73ba6b2fa1"
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"saved_mobilenet/mobilenetv2-method6.pth\", map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZSKl7MC-HYf"
   },
   "source": [
    "# Generate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kH2FQmbP9-aS"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def generate_confusion_matrix(model, data_loader, device, num_classes):\n",
    "    \"\"\"\n",
    "    Generate a confusion matrix for the model on the given data loader.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model\n",
    "        data_loader: DataLoader containing test data\n",
    "        device: Device to run inference on\n",
    "        num_classes: Number of classes in the dataset\n",
    "\n",
    "    Returns:\n",
    "        confusion_matrix: The generated confusion matrix\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize confusion matrix\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    # Collect all predictions and labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Save predictions and labels\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    for pred, label in zip(all_preds, all_labels):\n",
    "        confusion_matrix[label, pred] += 1\n",
    "\n",
    "    return confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, class_names):\n",
    "    \"\"\"\n",
    "    Plot and save a confusion matrix with class names.\n",
    "\n",
    "    Args:\n",
    "        confusion_matrix: The confusion matrix to plot\n",
    "        class_names: List of class names for the axes\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mobilenetv2_confusion_matrix.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azqzEqgv9-YM",
    "outputId": "a94b8082-e176-4a09-a115-260091d65c5f"
   },
   "outputs": [],
   "source": [
    "data_module = GarbageClassificationData(\n",
    "    batch_size=32,  # Use same batch size as training or larger if memory allows\n",
    "    num_workers=4,  # Adjust based on your system\n",
    "    img_size=224    # Same as used during training\n",
    ")\n",
    "data_module.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1a8fc1643232468c993c99eaddd93c29",
      "59aaca965815479fa6a191e5fb497b14",
      "51567224e8944703a0d9c56e4d917fe1",
      "31061e4cc2dd4ed89ebe718a73028f9b",
      "00b684e7c7884a509ca4e70c5ec410e5",
      "0c1e67f00c9c4558a66102ae2d3cf6ba",
      "4591dea6c3514926a06f9d898659af4e",
      "c43cae5200c849a48f27c6933eb27fd7",
      "d8c5ffd7272644e0a4bac6c49fc4528e",
      "5e8679f7158b48c9b3d635821c642b4a",
      "d215d3268fd645a0b85db1c2a349f629"
     ]
    },
    "id": "AraylOkc9-Vn",
    "outputId": "8bbe9073-92d8-4add-ae23-704d3760b8cd"
   },
   "outputs": [],
   "source": [
    "# Get class names\n",
    "idx_to_garbage = data_module.idx_to_garbage\n",
    "class_names = [idx_to_garbage[i] for i in range(len(idx_to_garbage))]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Generate confusion matrix\n",
    "test_loader = data_module.test_dataloader()\n",
    "conf_matrix = generate_confusion_matrix(model, test_loader, device, num_classes)\n",
    "\n",
    "# Plot and save confusion matrix\n",
    "plot_confusion_matrix(conf_matrix, class_names)\n",
    "\n",
    "# Calculate per-class metrics\n",
    "precision_per_class = np.zeros(num_classes)\n",
    "recall_per_class = np.zeros(num_classes)\n",
    "f1_per_class = np.zeros(num_classes)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    # True positives are on the diagonal\n",
    "    tp = conf_matrix[i, i]\n",
    "    # False positives are in the column (excluding true positive)\n",
    "    fp = np.sum(conf_matrix[:, i]) - tp\n",
    "    # False negatives are in the row (excluding true positive)\n",
    "    fn = np.sum(conf_matrix[i, :]) - tp\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    precision_per_class[i] = precision\n",
    "    recall_per_class[i] = recall\n",
    "    f1_per_class[i] = f1\n",
    "\n",
    "# Create a DataFrame for per-class metrics\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Precision': precision_per_class,\n",
    "    'Recall': recall_per_class,\n",
    "    'F1 Score': f1_per_class\n",
    "})\n",
    "\n",
    "# Display the table with formatted metrics\n",
    "pd.set_option('display.precision', 4)  # Set display precision to 4 decimal places\n",
    "print(\"\\n=== Per-Class Metrics ===\")\n",
    "print(metrics_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# Calculate and print overall metrics\n",
    "accuracy = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
    "macro_precision = np.mean(precision_per_class)\n",
    "macro_recall = np.mean(recall_per_class)\n",
    "macro_f1 = np.mean(f1_per_class)\n",
    "\n",
    "# Create a DataFrame for overall metrics\n",
    "overall_metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Macro Precision', 'Macro Recall', 'Macro F1 Score'],\n",
    "    'Value': [accuracy, macro_precision, macro_recall, macro_f1]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Overall Metrics ===\")\n",
    "print(overall_metrics_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# Optional: Create a visual table with matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.axis('off')\n",
    "table = plt.table(\n",
    "    cellText=np.column_stack((\n",
    "        class_names,\n",
    "        [f\"{x:.4f}\" for x in precision_per_class],\n",
    "        [f\"{x:.4f}\" for x in recall_per_class],\n",
    "        [f\"{x:.4f}\" for x in f1_per_class]\n",
    "    )),\n",
    "    colLabels=['Class', 'Precision', 'Recall', 'F1 Score'],\n",
    "    loc='center',\n",
    "    cellLoc='center',\n",
    "    colWidths=[0.3, 0.2, 0.2, 0.2]\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1.2, 1.5)\n",
    "plt.title(\"Per-Class Performance Metrics\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"class_metrics_table.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-w_rre2_-5Z"
   },
   "source": [
    "# Error Analysis Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bSzqECX9GWC"
   },
   "outputs": [],
   "source": [
    "def generate_error_analysis_heatmap(confusion_matrix, class_names):\n",
    "    \"\"\"Generate a normalized heatmap showing error patterns.\"\"\"\n",
    "    # Normalize by row (true labels)\n",
    "    row_sums = confusion_matrix.sum(axis=1, keepdims=True)\n",
    "    norm_conf_matrix = confusion_matrix / row_sums\n",
    "\n",
    "    # Create a mask for the diagonal (correct predictions)\n",
    "    np.fill_diagonal(norm_conf_matrix, 0)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(norm_conf_matrix, annot=True, fmt='.2f', cmap='Reds',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Error Distribution (Normalized Confusion Matrix with Diagonal Removed)')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"error_heatmap.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bjISboK79GTi",
    "outputId": "b569774e-dbf6-400c-8cc9-ec502ec525fc"
   },
   "outputs": [],
   "source": [
    "# Get class names from the data module\n",
    "idx_to_garbage = data_module.idx_to_garbage\n",
    "class_names = [idx_to_garbage[i] for i in range(len(idx_to_garbage))]\n",
    "\n",
    "# Now call the function with both required arguments\n",
    "generate_error_analysis_heatmap(conf_matrix, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYNYT2IqAhdL"
   },
   "source": [
    "# Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKJGDhnsAIQ3"
   },
   "outputs": [],
   "source": [
    "def analyze_prediction_confidence(model, data_loader, device, class_names):\n",
    "    \"\"\"Analyze the confidence of predictions by class.\"\"\"\n",
    "    model.eval()\n",
    "    correct_confidences = [[] for _ in range(len(class_names))]\n",
    "    incorrect_confidences = [[] for _ in range(len(class_names))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Analyzing confidence\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            # Get max probability (confidence) and predicted class\n",
    "            confidences, preds = torch.max(probabilities, dim=1)\n",
    "\n",
    "            # Store confidences by true class\n",
    "            for i, (conf, pred, label) in enumerate(zip(confidences, preds, labels)):\n",
    "                if pred == label:\n",
    "                    correct_confidences[label.item()].append(conf.item())\n",
    "                else:\n",
    "                    incorrect_confidences[label.item()].append(conf.item())\n",
    "\n",
    "    # Plot average confidence by class\n",
    "    avg_correct_conf = [np.mean(confs) if confs else 0 for confs in correct_confidences]\n",
    "    avg_incorrect_conf = [np.mean(confs) if confs else 0 for confs in incorrect_confidences]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.bar(x - width/2, avg_correct_conf, width, label='Correct Predictions')\n",
    "    plt.bar(x + width/2, avg_incorrect_conf, width, label='Incorrect Predictions')\n",
    "\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Average Confidence')\n",
    "    plt.title('Average Prediction Confidence by Class')\n",
    "    plt.xticks(x, class_names, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confidence_analysis.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Histogram of confidences for correct vs incorrect predictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Flatten lists for histogram\n",
    "    all_correct_conf = [conf for confs in correct_confidences for conf in confs]\n",
    "    all_incorrect_conf = [conf for confs in incorrect_confidences for conf in confs]\n",
    "\n",
    "    plt.hist(all_correct_conf, bins=20, alpha=0.6, label='Correct Predictions')\n",
    "    plt.hist(all_incorrect_conf, bins=20, alpha=0.6, label='Incorrect Predictions')\n",
    "\n",
    "    plt.xlabel('Confidence Score')\n",
    "    plt.ylabel('Number of Predictions')\n",
    "    plt.title('Distribution of Confidence Scores')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confidence_histogram.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "aed3361d7fed4fe9946128bc513f07c1",
      "5ffa22499e814d99bea9d1d3789f4282",
      "e34f62d921bc44168d0d5981aec38697",
      "394dd8eb148e4399bd7f284ed9dbfd2c",
      "508e3373977349d5aaf060864129c3f5",
      "97b946bb6ccc464c89a398b361c9db8e",
      "288d14f49dad4295b2cb83bfee1c02ba",
      "d582c48bdd6f4ceba6e9eb6307885196",
      "3a3f2b10a90041328bae8df641fc8acb",
      "f4ecfc4f074d49109744e16adc8b2f01",
      "52afe14e5d954745a0c6956a1015a496"
     ]
    },
    "id": "Pco8nOAJAIOA",
    "outputId": "d39a06bc-ce1f-4ef9-c1a4-c4eaa5163e2b"
   },
   "outputs": [],
   "source": [
    "analyze_prediction_confidence(model, test_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxkuiU1HA41-"
   },
   "source": [
    "# Misclassification Analysis with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gg9Y1QdMAIJ6"
   },
   "outputs": [],
   "source": [
    "def show_misclassified_examples(model, data_loader, device, class_names, num_examples=16):\n",
    "    \"\"\"Show examples of misclassified images.\"\"\"\n",
    "    model.eval()\n",
    "    misclassified_images = []\n",
    "    misclassified_labels = []\n",
    "    misclassified_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Find misclassified examples\n",
    "            incorrect_mask = (preds != labels)\n",
    "\n",
    "            if incorrect_mask.sum() > 0:\n",
    "                incorrect_images = images[incorrect_mask]\n",
    "                incorrect_labels = labels[incorrect_mask]\n",
    "                incorrect_preds = preds[incorrect_mask]\n",
    "\n",
    "                for img, true_label, pred_label in zip(incorrect_images, incorrect_labels, incorrect_preds):\n",
    "                    misclassified_images.append(img.cpu())\n",
    "                    misclassified_labels.append(true_label.item())\n",
    "                    misclassified_preds.append(pred_label.item())\n",
    "\n",
    "                    if len(misclassified_images) >= num_examples:\n",
    "                        break\n",
    "\n",
    "            if len(misclassified_images) >= num_examples:\n",
    "                break\n",
    "\n",
    "    # Display the misclassified images\n",
    "    num_to_show = min(len(misclassified_images), num_examples)\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(16, 16))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_to_show):\n",
    "        img = misclassified_images[i].permute(1, 2, 0).numpy()\n",
    "        # Denormalize if needed\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        # Show the image and add labels\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"True: {class_names[misclassified_labels[i]]}\\n\"\n",
    "                          f\"Pred: {class_names[misclassified_preds[i]]}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"misclassified_examples.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LrX6j7wvAIHP",
    "outputId": "80186522-2c8f-47c7-f490-0ce2691c2437"
   },
   "outputs": [],
   "source": [
    "show_misclassified_examples(model, test_loader, device, class_names, num_examples=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WNVi9KvAIEY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5GbTOCIAIBg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0oy5-tLAH-6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_hGaZllAH8D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
